{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5832d684-b3e9-4930-987d-b16528a12e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformerConfig, HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86750e2e-efdd-4da8-af56-0366914d3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_seq_lengths(total_length, min_length, max_length, rng):\n",
    "    too_many = rng.integers(min_length, max_length, min_length * total_length)\n",
    "    sequence_lengths = too_many[np.cumsum(too_many) <= total_length]\n",
    "    diff = total_length - np.sum(sequence_lengths)\n",
    "    sequence_lengths = sequence_lengths.tolist()\n",
    "    if diff >= min_length and diff <= max_length:\n",
    "        sequence_lengths += [diff]\n",
    "    return sequence_lengths\n",
    "    \n",
    "\n",
    "def generate_cum_parity(total_seq_len: int, rng):\n",
    "    seq_len = (total_seq_len - 2) // 2\n",
    "    assert seq_len > 0, total_seq_len\n",
    "    equals = np.array([2])\n",
    "    sep = 3\n",
    "    x = rng.integers(0, 2, seq_len)\n",
    "    running_x = np.cumsum(x) % 2\n",
    "    seq = np.concatenate([x, equals, running_x], axis=0)\n",
    "    seq = np.pad(seq, (1, total_seq_len - len(seq) - 1), mode='constant', constant_values=(sep, sep))\n",
    "    return seq\n",
    "\n",
    "\n",
    "def generate_packed_parity(total_seq_length, min_seq_length=6, max_seq_length=30, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    sep = 3\n",
    "    sequence_lengths = get_seq_lengths(total_seq_length, min_seq_length, max_seq_length, rng)\n",
    "    assert sum(sequence_lengths) <= total_seq_length\n",
    "    parities = [\n",
    "            generate_cum_parity(seq_len, stream) for seq_len, stream in zip(sequence_lengths, rng.spawn(len(sequence_lengths)))\n",
    "    ]\n",
    "    parities = np.concatenate(parities)\n",
    "    diff = total_seq_length - len(parities)\n",
    "    return np.pad(parities, (0, diff), mode='constant', constant_values=(sep, sep))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ac0b81-204c-42aa-99b6-fd557dc96089",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"d_model\": 128,\n",
    "    \"d_head\": 32,\n",
    "    \"n_heads\": 2,\n",
    "    \"d_mlp\": 512,\n",
    "    \"n_ctx\": 512,\n",
    "    \"n_layers\": 1,\n",
    "    \"d_vocab\": 4,\n",
    "    \"act_fn\": \"relu\"\n",
    "}\n",
    "\n",
    "config = HookedTransformerConfig(**cfg)\n",
    "model = HookedTransformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c634ac-e0e6-4600-8484-057b65703232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de81f97a-d9aa-4cd3-bf2b-584a0e166e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(10)\n",
    "parities = np.stack([ generate_packed_parity(512, 8, 32, stream) for stream in rng.spawn(512)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef4b98f6-8422-4e56-9653-2d4bd48eb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(torch.asarray(parities, device='cuda:0'), return_type='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be3c66e-1fcf-4767-b5e8-9d7c54f44beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0172ba01-3349-443e-89a6-63bce9b04a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CumulativeParityDataset:\n",
    "\n",
    "    def __init__(self, total_sequence_length: int, min_sequence_length: int, max_sequence_length: int, batch_size: int, rng_seed: int = 0):\n",
    "        super().__init__()\n",
    "        self.total_sequence_length = total_sequence_length\n",
    "        self.min_sequence_length = min_sequence_length\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.batch_size = batch_size\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    def next(self):\n",
    "        #worker_info = torch.utils.data.get_worker_info()\n",
    "        #if worker_info is not None:\n",
    "        #    all_rngs = [stream for stream in self.rng.spawn(worker_info.num_workers)]\n",
    "        #    rng = all_rngs[worker_info.id]\n",
    "        #else:\n",
    "        rng = self.rng\n",
    "        parities = [\n",
    "            generate_packed_parity(\n",
    "                self.total_sequence_length,\n",
    "                self.min_sequence_length,\n",
    "                self.max_sequence_length,\n",
    "                stream\n",
    "            ) for stream in rng.spawn(self.batch_size)\n",
    "        ]\n",
    "   \n",
    "        return torch.asarray(np.stack(parities, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "361f1a35-8cc6-4b67-87a1-9dbf47674b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = CumulativeParityDataset(512, 8, 30, 512, 10)\n",
    "loader = DataLoader(dataset, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aafc7e80-b835-4805-b376-ef01a1e18f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 0, 0,  ..., 1, 1, 3],\n",
       "        [3, 1, 1,  ..., 1, 0, 3],\n",
       "        [3, 1, 0,  ..., 1, 1, 3],\n",
       "        ...,\n",
       "        [3, 1, 0,  ..., 1, 0, 1],\n",
       "        [3, 0, 0,  ..., 3, 3, 3],\n",
       "        [3, 1, 0,  ..., 1, 0, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed7f7250-38ee-4b74-9e2a-58295dd4b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, num_steps, dataloader):\n",
    "\n",
    "    #loader = iter(dataloader)\n",
    "\n",
    "    with trange(num_steps) as t:\n",
    "        for i in t:\n",
    "            data = dataloader.next()\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(data.to('cuda:0'), return_type='loss')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                t.set_postfix(loss=loss.item(), lr=scheduler.get_last_lr())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd12a4f3-dd35-4467-8cff-adc5fe28101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_warmup = 100\n",
    "num_steps = 10_000\n",
    "seed = 0\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    \"d_model\": 128,\n",
    "    \"d_head\": 32,\n",
    "    \"n_heads\": 2,\n",
    "    \"d_mlp\": 512,\n",
    "    \"n_ctx\": 512,\n",
    "    \"n_layers\": 1,\n",
    "    \"d_vocab\": 4,\n",
    "    \"act_fn\": \"relu\"\n",
    "}\n",
    "\n",
    "config = HookedTransformerConfig(**cfg)\n",
    "model = HookedTransformer(config)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "warmup = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.001, end_factor=1.0, total_iters=num_warmup)\n",
    "annealing = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(num_steps - num_warmup), eta_min=1.0e-6)\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, [warmup, annealing], milestones=[num_warmup])\n",
    "\n",
    "dataset = CumulativeParityDataset(512, 6, 32, 512, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57967878-da9d-4704-bf7d-0356c47fbf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63462facaa624469b8c336a909396803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, optimizer, scheduler, num_steps, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5b14d-2ce1-4768-a673-03de7d09d3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
